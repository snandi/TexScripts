\documentclass[11pt]{extarticle} %extarticle for fontsizes other than 10, 11 And 12
%\documentclass[11p]{article}

%%%%%%%%%%%%%%%%%%%%%%%% Packages %%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amscd}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsxtra}
\usepackage{bbold}
%\usepackage{bigints}
\usepackage{color}
\usepackage{dsfont}
\usepackage{enumerate}
\usepackage[mathscr]{eucal}
%\usepackage{fancyhdr}
\usepackage{float}
%\usepackage{fullpage} %% Dont use this for beamer presentations
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{indentfirst}
\usepackage{latexsym}
\usepackage{listings}
\usepackage{lscape}
\usepackage{mathtools}
\usepackage{microtype}
\usepackage{natbib}
\usepackage{pdfpages}
\usepackage{verbatim}
\usepackage{wrapfig}
\usepackage{xargs}
\DeclareGraphicsExtensions{.pdf,.png,.jpg, .jpeg}

%%%%%%%%%%%%%%%%%%%%%%%% Commands %%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\Sup}{\textsuperscript}
\newcommand{\Exp}{\mathds{E}}
\newcommand{\Prob}{\mathds{P}}
\newcommand{\Z}{\mathds{Z}}
\newcommand{\Ind}{\mathds{1}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\bes}{\begin{equation*}}
\newcommand{\ees}{\end{equation*}}
\newcommand{\union}{\bigcup}
\newcommand{\intersect}{\bigcap}
\newcommand{\Ybar}{\overline{Y}}
\newcommand{\ybar}{\bar{y}}
\newcommand{\Xbar}{\overline{X}}
\newcommand{\xbar}{\bar{x}}
\newcommand{\betahat}{\hat{\beta}}
\newcommand{\Yhat}{\widehat{Y}}
\newcommand{\yhat}{\hat{y}}
\newcommand{\Xhat}{\widehat{X}}
\newcommand{\xhat}{\hat{x}}
\newcommand{\E}[1]{\operatorname{E}\left[ #1 \right]}
%\newcommand{\Var}[1]{\operatorname{Var}\left( #1 \right)}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\Cov}[2]{\operatorname{Cov}\left( #1,#2 \right)}
\newcommand{\N}[2][1=\mu, 2=\sigma^2]{\operatorname{N}\left( #1,#2 \right)}
\newcommand{\bp}[1]{\left( #1 \right)}
\newcommand{\bsb}[1]{\left[ #1 \right]}
\newcommand{\bcb}[1]{\left\{ #1 \right\}}
\newcommand*{\permcomb}[4][0mu]{{{}^{#3}\mkern#1#2_{#4}}}
\newcommand*{\perm}[1][-3mu]{\permcomb[#1]{P}}
\newcommand*{\comb}[1][-1mu]{\permcomb[#1]{C}}

%%%%%%%%%%%%%%%%%%% To change the margins and stuff %%%%%%%%%%%%%%%%%%%
\geometry{left=1in, right=1in, top=1in, bottom=0.8in}
%\setlength{\voffset}{0.5in}
%\setlength{\hoffset}{-0.4in}
%\setlength{\textwidth}{7.6in}
%\setlength{\textheight}{10in}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
%\SweaveOpts{concordance=TRUE}
\bibliographystyle{plain}  %Choose a bibliograhpic style

\title{Functional Principal Component Analysis for Longitudinal and Survival Data\\ by Fang Yao, Statistica Sinica, 2007}
\author{Subhrangshu Nandi\\
  Project Report, 
  Stat 741: Survival Analysis}
\date{April 21, 2015}
%\date{}

\maketitle

%% \begin{center}
%% {\Large{Comparing different clustering techniques in analyzing gene-expression data}}\\
%% Subhrangshu Nandi\\
%% Stat 760: Multivariate Analysis\\
%% Project Proposal\\
%% November 25, 2014
%% \end{center}

\subsection*{Introduction}
This paper uses functional principal component analysis to jointly model longitudinal and survival data. The longitudinal covariates could potentially have measurement or observation error. 

\subsection*{Data}
The dataset that motivated this research is as follows
\begin{itemize}
\item 467 HIV-infected patients - diagnosed with AIDS or two CD4 counts $< 300$
\item Two different drugs for treatment - ddC, ddI
\item CD4 observed at 5 time points - 0, 2, 6, 12, 18 months (Observed longitudinal covariate $Y_{i}(t_{ij})$)
\item $X_{i}(t_{ij}): $ Unobserved longitudinal covariate is the physiological response to the treatment
\item Goal: Investigate relationship between treatment effect of two drugs with survival
\end{itemize}

\subsection*{Joint modeling of longitudinal and survival data}
%\frametitle{Longitudinal Process}
% Breakdown of the likelihood by the different variables
\begin{itemize}
\item Let $\mu(t):$ the overall mean function; $Z_i(t):$ vector of covariates (example, treatment indicator), Then 
$ \mu_i(t) = \mu(t|Z_i) = \mu(t) + \beta^T Z_i(t), \ \ t \in [0, \tau] $
\item $X_i(t):$ the realization of the latent longitudinal process for the $i^{th}$ individual is 
$ X_i (t) = \mu_i (t) + \sum_{k=1}^{K} \xi_{ik} \phi_k (t) $
\item $\epsilon _{ij} \sim  \mathcal{N}(0, \sigma^2): $ Uncorrelated measurement errors, then the sub-model for the longitudinal covariate $Y_{ij}$ is  
$ Y_{ij} =  X_i(t_{ij}) + \epsilon _{ij} = \mu(t_{ij}) + Z_i(t_{ij})^T\beta + \sum_{k=1}^{K} \xi_{ik} \phi_k (t_{ij})+ \epsilon_{ij}$
\item Fitting overall mean function, with B-Splines, we have 
$ \mu(t) =  \mathbf{B}_p(t)^T \mathbf{\alpha},\ \ \alpha = (\alpha_1, \dots, \alpha_p)^T $
\item Fitting each eigen function, with another set of B-Splines, we have
$ \sum_{k=1}^{K} \xi_{ik} \phi_k (t_{ij}) =  \sum_{k=1}^{K} \xi_{ik} \widetilde{\mathbf{B}}_q(t)^T \mathbf{\theta _k},\ \ \theta_{k} = (\theta_{1k}, \dots, \theta_{qk})^T $
\item Finally, the Cox Model, with some more covariates $V(t)$ is 
$ h_i(t) = h_0(t)\exp\{\gamma X_i(t) + V_i(t)^T \zeta \}$
\item Final parameter vector of interest is 
$ \Omega = \left\{ \gamma, \zeta, h_0(\cdot), \alpha, \beta, \Theta, \Lambda, \sigma^2 \right\} $
with tuning parameters: $p, q, K$
\end{itemize}
The estimation procedure is as follows: (1) Iterative selection procedure for choosing knots (p, q), for the B-splines, and number of PCAs (K); (2) qui-quantile knots are chosen, instead of equi-distant (to not underweight time points with fewer observations); (3) AIC used for choosing these tuning parameters; (4) EM algorithm is used for parameter estimation $ \Omega = \left\{ \gamma, \zeta, h_0(\cdot), \alpha, \beta, \Theta, \Lambda, \sigma^2 \right\} $; (5) In E-step, Monte Carlo integration used instead of Gaussian-Hermite quadrature; (6) Newton-Raphson algorithm used to estimate the Cox-model 
$ \hat{\eta}^{(l)} = \hat{\eta}^{(l-1)} + I^{-1}_{\hat{\eta}^{(l-1)}} S_{\hat{\eta}^{(l-1)}},\ \ \eta = (\gamma, \zeta^T)$. \\
Hence, there are three iterative procedures, thus necessitating a computationally efficient process. 

\subsection*{Contribution of paper}
This work is based on {\bf{Brown, E. R.}}, Ibrahim, J. G. and DeGruttola, V. (2005). A flexible B-spline model for multiple
longitudinal biomarkers and survival. {\emph{Biometrics}} {\bf{61}}, 64-73. This paper proposes a nonparametric approach for {\underline{jointly}} modelling
\begin {itemize}
\item Fast and efficient implementation, by choosing few FPC's
\item No known structure of underlying longitudinal process
\item Iterative selection procedure for choosing tuning parameters (\# of eigen functions, \# of knots of spline models), using AIC 
\item EM algorithm used for joint estimation of parameters
\end{itemize}

\subsection*{Critical appreciation}
\begin{itemize}
\item Contribution is not significant, when compared to the work done by Brown, et. al. Below is a screenshot from this paper, which articulates the contribution: \\
\includegraphics[scale=0.45]{ImprovementText.jpg} \\
\item Marginal improvement over using just linear fit and random effects for the longitudinal covariate
\item Simulation not comprehensive - Considering the complicated framework of estimating the parameters, after three iterative procedures, the simulation example was too simple. It does not illustrate the main contribution of the paper. 
\item Could have applied this to more complex data - This methodology should have been tested to a more complex dataset, with more observations of the longitudinal covariate. 
\item No large sample results
\end{itemize}


%\newpage
%\bibliography{bibTex_Reference}
%\bibliography{research}

\end{document}
